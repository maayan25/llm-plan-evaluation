# Author: Ma'ayan Armony <maayan.armony@kcl.ac.uk>
# Class to attempt to increase the validity of aspects of the invalid plan

import os
from copy import deepcopy

from tarski.io import PDDLReader

from common import parse_goal_state, parse_init_state, get_largest_subsequence
from evaluate_plan import Plan
from evaluate_plan_per_action import EvaluatePlanPerAction
from utils import get_config_dir, get_instance_from_config, set_configuration, \
    parse_plan

# Run the file from its directory
current_dir = os.getcwd()
project_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))
parent_dir = os.path.abspath(os.path.join(project_dir, os.pardir))

llm_project_dir = os.path.join(parent_dir, "LLM-Planning-PlanBench/")

def find_state(s, states) -> int:
    """
    Check if a certain state is in the plan, and if it is, return its index
    :param s: the state to search for
    :param states: the plan states to search in
    :return: the index of the state in the plan (or -2 if not found)
    """
    index = -2

    for state in states:
        is_state = True
        # Check if all preds in s are in this state
        for pred in s:
            if pred not in state:
                is_state = False
        if is_state:
            index = states.index(state)
            break

    # print(f"State: {s} found at index {index}")
    return index


class InitialPlanRecovery:
    def __init__(self, curr: Plan, evaluator: EvaluatePlanPerAction, gt: list[str], config="blocksworld_3", instance=2):
        self.config_name = config
        self.instance_id = instance

        self.curr_plan: Plan = curr  # the plan generated by the LLM
        self.gt: Plan = Plan(gt, gt, True, config, instance, unique_id=f"{self.curr_plan.unique_id}_gt")  # a Plan object for the GT plan
        self.evaluator: EvaluatePlanPerAction = evaluator  # the evaluator object for the generated plan
        self.optimality: dict = evaluator.optimality   # the optimality values for the generated plan
        self.gt_plan: list[str] = gt         # the ground truth plan from PlanBench
        if not self.gt_plan:
            print(f"Ground truth plan is empty for domain: {config}, instance: {instance}")
            self.first_action = ""
            self.last_action = ""
        else:
            self.first_action = self.gt_plan[0]  # 1st action from GT plan
            self.last_action = self.gt_plan[-1]  # final action from GT plan

        self.domain_path = get_config_dir(config)
        self.domain_file = f"{self.domain_path}/generated_domain.pddl"
        self.problem_file = get_instance_from_config(config, self.domain_path, instance)

        self.reader = PDDLReader(raise_on_error=True)
        self.domain = self.reader.parse_domain(self.domain_file)  # TODO returns none
        self.problem = self.reader.parse_instance(self.problem_file)

        self.init = parse_init_state(self.problem)
        self.goal = parse_goal_state(self.problem)
        self.actions = self.problem.actions

        self.search_steps_to_validity(self.curr_plan)
        self.correct_part = []
        self.complementary_plan = []
        _, _, self.improved_plan = self.improve_plan(self.curr_plan, find_state(self.goal, self.curr_plan.simulate_states()), is_curr=True)
        print("=== DEBUG ===")
        print("self.correct_part:", self.correct_part)
        print("self.complementary_plan:", self.complementary_plan)
        print("Are they overlapping?:", any(x in self.complementary_plan for x in self.correct_part))

        self.candidate_plan = self.find_candidate_plan()
        self.search_steps_to_validity(self.candidate_plan)
        self.improved_candidate_plan = self.candidate_plan

        self.subseq_plan = self.search_subseqs(self.curr_plan)
        self.search_steps_to_validity(self.subseq_plan)
        self.improved_subseq_plan = self.subseq_plan

        self.subseq_candidate_plan = self.search_subseqs(self.candidate_plan)
        self.search_steps_to_validity(self.subseq_candidate_plan)
        self.improved_subseq_candidate_plan = self.subseq_candidate_plan
        # _, self.subseq_candidate_comp_plan, self.improved_subseq_candidate_plan = self.improve_plan(self.subseq_candidate_plan, find_state(self.goal, self.subseq_candidate_plan))

        print(f"Instance: {self.instance_id}")
        print(f"GT plan: {self.gt_plan}")
        print(f"Curr plan: {self.curr_plan.get_plan()} (valid: {self.curr_plan.is_valid})")

    def find_candidate_plan(self) -> Plan:
        """
        Get the best plan found, whether it is the current plan or the optimal plan found during the evaluation
        process.
        :return: the best plan found
        """
        optimal_plan = self.optimality.get("optimal_plan")

        if optimal_plan:
            opt_validity = optimal_plan.is_valid
            if not opt_validity and self.curr_plan.is_valid:
                # If the optimal plan is not valid, but the current plan is, return the current plan
                return self.curr_plan
            else:
                return optimal_plan
        else:
            return self.curr_plan

    def search_steps_to_validity(self, plan: Plan) -> list:
        """
        Search for the steps to validity in the plan; the steps to validity are the steps that are needed to get from
        the current plan to the ground truth plan.
        This is based on actions, not on the states:
            - adding actions to it
            - removing actions from it
            - changing the order of actions in it
            - changing the variables of actions in it
        :return: the steps to validity as a dictionary of what to do and the action to do it
        """
        # TODO take care of repeated actions; also if have time, check where variables need swapping
        # TODO need to check if the action is repaired, if it needs reordering

        steps_to_validity = []
        better_plan_lst = []
        no_of_repairs = 0

        improved = False

        # Remove the auxiliary actions from the plan
        plan_list = plan.get_plan()
        for i in range(len(plan_list)):
            try:
                action = plan_list[i]
                if plan.plan_trace[i] != "redundant":
                    # remove the auxiliary actions from the plan trace
                    better_plan_lst.append(action)
                else:
                    steps_to_validity.append(("remove_action", action))
                    improved = True
            except KeyError as e:
                print(f"KeyError: {i} for plan {plan_list} and plan trace {plan.plan_trace}")

        if improved:
            # Create a new plan with these actions, to check the steps to validity (positioning might change now)
            better_plan = Plan(better_plan_lst, self.gt_plan, False, self.config_name, self.instance_id, unique_id=f"{plan.unique_id}_better")
        else:
            better_plan = plan

        if better_plan.is_valid:
            # Plan is valid and no steps to validity needed for plan (except for the redundant actions if they exist)
            plan.set_steps_to_validity(steps_to_validity)
            return steps_to_validity

        plan_trace = better_plan.plan_trace
        assert len(better_plan_lst) <= len(self.gt_plan)  # only action pairs should remain (actions from GT could be missing)

        # On the new plan trace, add the fixes + reorder for every action which is not in the right position
        for i in range(len(better_plan_lst)):
            action = better_plan_lst[i]
            if action in self.gt_plan:
                if plan_trace[i] == "position":
                    continue
                else:  # plan_trace[i] == "correct"
                    steps_to_validity.append(("reorder_action", action))
            else:
                if plan_trace[i] == "same_act":
                    # If the action is in the GT plan, but in the wrong position, it needs to be moved
                    no_of_repairs += 1
                    steps_to_validity.append(("fix_variables", action))
                elif plan_trace[i] == "diff_act":
                    # If the action has little similarity to the GT action, it needs to be fixed
                    no_of_repairs += 1
                    steps_to_validity.append(("fix_action", action))
                else: # plan_trace[i] == "auxiliary"
                    # If the action is not in the GT plan, it needs to be removed
                    steps_to_validity.append(("remove_action", action))

        # TODO actually check if self.action_pairs if this action has a pair, if not, add it to the steps to validity
        for action in self.gt_plan:
            if action not in plan_list:
                if no_of_repairs > 0:
                    no_of_repairs -= 1
                else:
                    # The action is not in the plan, it needs to be added
                    steps_to_validity.append(("add_action", action))

        plan.set_steps_to_validity(steps_to_validity)
        return steps_to_validity

    def improve_plan(self, plan: Plan, goal_index: int, is_curr = False) -> (list, list, Plan):
        """
        Attempt to improve the plan by generating subplans to get to the initial and goal states
        :return: the best plan found
        """
        # TODO need to check if actions need to be added to the beginning of the plan
        # TODO check for any state if it is in the plan, not only consecutive states.. i.e. skip later as well
        plan_list = plan.get_plan()
        correct_part = []
        complementary_plan = []
        improved_plan = plan

        if len(self.gt_plan) == 0:
            # Error in original plan generation, no GT to recover with
            return complementary_plan, improved_plan
        elif len(plan_list) == 0:
            # If the plan is empty, return the GT plan
            if is_curr:
                self.complementary_plan = self.gt_plan
            complementary_plan = self.gt_plan
            print(f"Plan was empty, comp plan is GT plan")
            improved_plan = Plan(complementary_plan, plan.gt_plan, False, self.config_name, self.instance_id, unique_id=f"{plan.unique_id}_improved")
            return [], complementary_plan, improved_plan

        # TODO should not happen, does it?
        if not plan.simulation_possible:
            if len(plan_list) > 0:
                if is_curr:
                    self.complementary_plan = self.gt_plan
                complementary_plan = self.gt_plan
                # last_state = self.init
                print(f"Plan was not simulated, comp plan is GT plan")
            else:
                # If the plan is empty, return the GT plan
                if is_curr:
                    self.complementary_plan = self.gt_plan
                complementary_plan = self.gt_plan
                # last_state = self.init
                print(f"Plan was empty, comp plan is GT plan")

            improved_plan = Plan(complementary_plan, plan.gt_plan, False, self.config_name,
                                 self.instance_id, unique_id=f"{plan.unique_id}_improved")
        else:
            if goal_index != -2: # the goal state is in the plan
                valid_plan = plan_list[:goal_index]  # get the plan up to the goal state
                self.correct_part = plan_list[:goal_index]
                improved_plan = Plan(valid_plan, plan.gt_plan, plan.is_valid, self.config_name, self.instance_id)
                if not improved_plan.is_valid:
                    print(f"improved plan: {improved_plan.get_plan()} (valid: {improved_plan.is_valid})")
                    print(f"for GT plan: {self.gt_plan}")
                # assert improved_plan.is_valid # Plan up to the goal state should be valid
            # If the goal state is not in the plan, regenerate the plan from the last state that is in the GT plan
            else:
                executable = plan.analysis.get("executable")
                last_act = plan.analysis.get("action")

                if executable:  # the sequence of actions can be executed (not necessarily to the goal state)
                    last_state_ind, last_state = self.compare_plan_states(plan)
                    print(f"DEBUG CORRECT: Plan is executable")
                    # last_state = self.curr_plan.states[-1]
                else:
                    # plan is not executable from this point (unmet dependencies)
                    print(f"DEBUG CORRECT: curr plan: {self.curr_plan.get_plan()} and GT plan: {self.gt_plan}")
                    print(f"DEBUG CORRECT: Plan is not executable from this point, last action: {last_act}")
                    if last_act:
                        last_act_index = plan_list.index(last_act[0])
                        last_state_ind, last_state = self.compare_plan_states(plan, last_act_index)
                    else: # no last action found, simulation failed (should not happen)
                        last_state = self.init
                        last_state_ind = 0

                print(f"DEBUG: Last state index: {last_state_ind}, last state: {last_state}")

                correct_part = plan_list[:last_state_ind]
                print(f"DEBUG Correct part: {correct_part}")
                complementary_plan = self.generate_subplan(init=last_state, goal=self.goal)
                if is_curr:
                    self.correct_part = self.curr_plan.get_plan()[:self.curr_plan.states.index(last_state)]
                    self.complementary_plan = self.generate_subplan(init=last_state, goal=self.goal)

                full_plan_list = deepcopy(correct_part) + deepcopy(complementary_plan)
                improved_plan = Plan(full_plan_list, plan.gt_plan, False, self.config_name, self.instance_id, unique_id=f"{plan.unique_id}_improved")

                if not improved_plan.is_valid:
                    print(f"WARNING: Improved plan is not valid, but should be. "
                          f"\n Improved plan: {improved_plan.get_plan()} (valid: {improved_plan.is_valid})")

        # TODO UNCOMMENT after debugging correct part and complementary plan
        # Run evaluation on the improved plan
        if not improved_plan.is_valid:
            self.evaluator.evaluate_plan(improved_plan)
        else:
            self.evaluator.evaluate_valid_plan(improved_plan)

        print(f"Improved plan: {improved_plan.get_plan()} (valid: {improved_plan.is_valid}) "
              f"for curr_plan? {plan.get_plan() == self.curr_plan.get_plan()} "
              f"\n where correct part: {correct_part} \n and complementary plan: {complementary_plan}")

        return deepcopy(correct_part), deepcopy(complementary_plan), improved_plan

    def compare_plan_states(self, plan: Plan, plan_index: int = -1) -> (int, list[str]):
        """
        Compare the plan states to the ground truth states to find the divergence point; if there is a divergence,
        check whether the next state is somewhere else in the plan, and continue from there; if not, regenerate the plan
        from the last state that is executable.
        :param plan: the plan generated by the LLM
        :param plan_index: (optional) index to specify where the plan is not executable anymore, to not look or states from
        that point onwards.
        :return: the last state that is reachable in the plan
        """
        gt_states = self.gt.states
        executable_plan = plan.get_plan()[:plan_index]
        curr_states = plan.states

        i = 0
        # print(
        #     f"DEBUG STATE: length of executable plan: {len(executable_plan)} and number of states: {len(plan.states)} \n"
        #     f"DEBUG STATE: length of GT {len(self.gt_plan)} and number of states {len(gt_states)} \n")
        print(f"DEBUG SIM: Plan States: {curr_states} \n And GT states: {gt_states} \n")

        for state in gt_states:
            # Check the index of the state in the plan
            index = find_state(state, curr_states)
            # print(f"DEBUG STATE: State: {state} found at index {index} in plan")
            # If state from GT is found in the generated plan, and we're not at the end of the generated plan, go on
            if index != -2:
                i = index
            elif len(executable_plan) >= i:
                # Next state does not exist in the plan, so regenerate the plan from the last state that is executable
                return i, curr_states[i]
            else:
                # Continue to the next state in the GT plan because maybe it is in the plan
                # return plan.states[i]
                continue

        return i, curr_states[i]
        # return self.goal
        # return plan.states[len(gt_states) - 1]  # if all states are in the plan, return the last state in the gt plan

    def search_subseqs(self, plan: Plan) -> Plan:
        """
        Search within the subsets and subsequences of the plan whether a valid plan can be found, or one that contains
        the goal state.
        :param plan: the plan to search within
        :return: the best plan found
        """
        largest_subsequence = Plan(plan.largest_subsequence, self.gt_plan, False, self.config_name, self.instance_id, unique_id=f"{plan.unique_id}_subseq")
        largest_subset = Plan(plan.largest_subset, self.gt_plan, False, self.config_name, self.instance_id, unique_id=f"{plan.unique_id}_subset")

        # Valid plan is the best plan, or one which contains the goal state
        if largest_subset.is_valid:
            return largest_subset
        elif largest_subset.is_valid:
            return largest_subsequence
        elif find_state(self.goal, largest_subsequence.states) != -2:
            return largest_subsequence
        elif find_state(self.goal, largest_subsequence.states) != -2:
            return largest_subsequence

        # Check all possible subsets
        for i in range(len(plan.get_plan())):
            subset = Plan(plan.get_plan()[i:], self.gt_plan, False, self.config_name, self.instance_id, unique_id=f"{plan.unique_id}_subset_{i}")
            if subset.is_valid or find_state(self.goal, subset.states) != -2:
                return subset

        return largest_subsequence

    def generate_subplan(self, init, goal) -> list[str]:
        """
        Create a sub-plan from to get to the specified goal from the specified initial state by calling the planner
        :return: the generated subplan
        """
        FD_PATH = os.path.join(llm_project_dir, "planner_tools/downward")
        problem_file = self.amend_problem_file(init, goal)
        if init != self.init:
            with open(problem_file, "r") as f:
                print(f"Amended problem file: {f.read()}")
        cmd = f"timeout 20s {FD_PATH}/fast-downward.py {self.domain_file} {problem_file} --search \"astar(lmcut())\" > /dev/null"
        os.system(cmd)
        plan_file = "sas_plan"
        try:
            with open(plan_file) as f:
                plan = [line.rstrip() for line in f][:-1]
                readable_plan = '\n'.join(plan)
                # print(f"Generated plan: {readable_plan.split('\n')}")
            os.remove(plan_file)
            return parse_plan(readable_plan)
        except FileNotFoundError:
            print("No plan found for this instance")
            return []

    def amend_problem_file(self, init: list[str], goal: list[str]):
        """
        Create amended problem file to reflect the new initial and goal states
        :param init: the initial state
        :param goal: the goal state
        :return: the new problem file
        """
        with open(self.problem_file, "r") as f:
            lines = f.readlines()

        print(f"old init: {self.init}")
        print(f"new init: {init}")

        print(f"old goal: {self.goal}")
        print(f"new goal: {goal}")

        new_lines = []
        inside_init = False
        inside_goal = False

        for i, line in enumerate(lines):
            if "(:init" in line:
                inside_init = True
                new_lines.append("(:init\n")
                for pred in init:
                    new_lines.append(f"{pred}\n")
                new_lines.append(")\n")
                continue  # Skip adding this line

            if "(:goal" in line:
                inside_goal = True
                new_lines.append("(:goal\n  (and\n")
                for pred in goal:
                    new_lines.append(f"{pred}\n")
                new_lines.append("))\n)\n")
                continue  # Skip adding this line

            if inside_init:
                if line.strip() == ")":  # end of (:init) block
                    inside_init = False
                continue  # Skip all lines of old init
            elif inside_goal:
                if line.strip() == "))":  # end of (:goal (and)) block
                    inside_goal = False
                continue  # Skip lines of old goal
            else:
                # If not inside an init or goal block, copy the line
                new_lines.append(line)

        new_problem_file = self.problem_file.replace(".pddl", "_amended.pddl")
        with open(new_problem_file, "w") as f:
            f.writelines(new_lines)

        return new_problem_file

if __name__ == "__main__":
    # configuration
    project = "llm_planning_analysis"  # llm_planning_analysis / plan-bench
    domain = "blocksworld_3"  # blocksworld_3, logistics
    model = "qcode"  # qwen, llama, qcode, llama_instruct
    task = ""  # "" -> "_one_shot", "_state_tracking", "_pddl", "_zero_shot"
    temp = 0.1
    top_p = 1
    params = set_configuration(model=model, task=task, domain=domain, project=project, temp=temp, top_p=top_p)

    filepath = f"{parent_dir}/LLM-Planning-PlanBench/{project}/results/{domain}/temp_{temp}_top_p_{top_p}/{model}/task_1_plan_generation{task}.json"
    instance_id = 2
    gen_plan = parse_plan("(unstack c a)\n(put-down c)\n(unstack a b)\n(put-down a)\n(pick-up b)\n(stack b a)\n(pick-up c)\n(stack c b)\n")
    gt_plan = parse_plan("(pick-up a)\n(stack a c)\n(pick-up b)\n(stack b a)\n")